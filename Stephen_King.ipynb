{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stephen King.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzoF3NvD6N7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open('Stephen King.txt')\n",
        "story = file.read()\n",
        "file.close()\n",
        "story = story.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2zF73n37AgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = sorted(set(story))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzXw4jRI8HUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_to_num = dict((j,i) for i,j in enumerate(vocab))\n",
        "num_to_vocab = dict((i,j) for i,j in enumerate(vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEIbD6yl8rQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len = 100\n",
        "sequence = []\n",
        "target = []\n",
        "for i in range(len(story)-seq_len-1):\n",
        "  sequence.append(story[i:i+seq_len])\n",
        "  target.append(story[i+seq_len])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlHDwmAJ-w5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_encode = []\n",
        "target_encode = []\n",
        "for i in sequence:\n",
        "  temp = []\n",
        "  for j in i:\n",
        "    temp.append(vocab_to_num[j])\n",
        "  sequence_encode.append(temp)\n",
        "for i in target:\n",
        "  target_encode.append(vocab_to_num[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NFtfvkSAwnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sequence_encode = np.array(sequence_encode)\n",
        "target_encode = np.array(target_encode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXUdrml6BgN4",
        "colab_type": "code",
        "outputId": "ff289d6b-a1ce-4726-8e32-ee728624199c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sequence_encode.shape, target_encode.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(122769, 100) (122769,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50RyriMVBqgR",
        "colab_type": "code",
        "outputId": "fb16dbc6-0a7e-435d-f1be-7bffc2c809a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import CuDNNLSTM, Embedding, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSO71OdWCA_s",
        "colab_type": "code",
        "outputId": "70f4177f-a409-46c7-9dbc-da5a703984ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab), 10, input_length=seq_len, trainable=True))\n",
        "model.add(CuDNNLSTM(512, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(CuDNNLSTM(512, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(vocab), activation= 'softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "ck = ModelCheckpoint('/content/drive/My Drive/stephen_king2.hdf5', monitor='loss', verbose=1, save_best_only=True, mode='auto')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 10)           520       \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 100, 512)          1073152   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 512)          0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_2 (CuDNNLSTM)     (None, 512)               2101248   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 52)                26676     \n",
            "=================================================================\n",
            "Total params: 3,201,596\n",
            "Trainable params: 3,201,596\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrIYQaSxC7Bo",
        "colab_type": "code",
        "outputId": "c01adb05-3fa2-4995-d662-4604d451a081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(sequence_encode, target_encode, batch_size=64, epochs=40, callbacks=[ck], verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "122769/122769 [==============================] - 92s 746us/step - loss: 2.4894 - acc: 0.2863\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.48939, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 2/40\n",
            "122769/122769 [==============================] - 85s 690us/step - loss: 1.9357 - acc: 0.4281\n",
            "\n",
            "Epoch 00002: loss improved from 2.48939 to 1.93574, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 3/40\n",
            "122769/122769 [==============================] - 85s 689us/step - loss: 1.6655 - acc: 0.5004\n",
            "\n",
            "Epoch 00003: loss improved from 1.93574 to 1.66552, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 4/40\n",
            "122769/122769 [==============================] - 84s 688us/step - loss: 1.4872 - acc: 0.5484\n",
            "\n",
            "Epoch 00004: loss improved from 1.66552 to 1.48718, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 5/40\n",
            "122769/122769 [==============================] - 85s 690us/step - loss: 1.3461 - acc: 0.5865\n",
            "\n",
            "Epoch 00005: loss improved from 1.48718 to 1.34607, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 6/40\n",
            "122769/122769 [==============================] - 85s 692us/step - loss: 1.2235 - acc: 0.6216\n",
            "\n",
            "Epoch 00006: loss improved from 1.34607 to 1.22347, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 7/40\n",
            "122769/122769 [==============================] - 85s 694us/step - loss: 1.1161 - acc: 0.6520\n",
            "\n",
            "Epoch 00007: loss improved from 1.22347 to 1.11606, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 8/40\n",
            "122769/122769 [==============================] - 85s 691us/step - loss: 1.0207 - acc: 0.6805\n",
            "\n",
            "Epoch 00008: loss improved from 1.11606 to 1.02072, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 9/40\n",
            "122769/122769 [==============================] - 85s 691us/step - loss: 0.9380 - acc: 0.7038\n",
            "\n",
            "Epoch 00009: loss improved from 1.02072 to 0.93798, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 10/40\n",
            "122769/122769 [==============================] - 85s 691us/step - loss: 0.8652 - acc: 0.7272\n",
            "\n",
            "Epoch 00010: loss improved from 0.93798 to 0.86520, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 11/40\n",
            "122769/122769 [==============================] - 85s 690us/step - loss: 0.8069 - acc: 0.7435\n",
            "\n",
            "Epoch 00011: loss improved from 0.86520 to 0.80688, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 12/40\n",
            "122769/122769 [==============================] - 85s 689us/step - loss: 0.7569 - acc: 0.7578\n",
            "\n",
            "Epoch 00012: loss improved from 0.80688 to 0.75687, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 13/40\n",
            "122769/122769 [==============================] - 85s 690us/step - loss: 0.7138 - acc: 0.7717\n",
            "\n",
            "Epoch 00013: loss improved from 0.75687 to 0.71375, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 14/40\n",
            "122769/122769 [==============================] - 85s 689us/step - loss: 0.6831 - acc: 0.7796\n",
            "\n",
            "Epoch 00014: loss improved from 0.71375 to 0.68313, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 15/40\n",
            "122769/122769 [==============================] - 84s 686us/step - loss: 0.6557 - acc: 0.7874\n",
            "\n",
            "Epoch 00015: loss improved from 0.68313 to 0.65574, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 16/40\n",
            "122769/122769 [==============================] - 84s 688us/step - loss: 0.6277 - acc: 0.7962\n",
            "\n",
            "Epoch 00016: loss improved from 0.65574 to 0.62770, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 17/40\n",
            "122769/122769 [==============================] - 84s 686us/step - loss: 0.6101 - acc: 0.8009\n",
            "\n",
            "Epoch 00017: loss improved from 0.62770 to 0.61008, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 18/40\n",
            "122769/122769 [==============================] - 84s 686us/step - loss: 0.6011 - acc: 0.8022\n",
            "\n",
            "Epoch 00018: loss improved from 0.61008 to 0.60112, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 19/40\n",
            "122769/122769 [==============================] - 84s 687us/step - loss: 0.5934 - acc: 0.8041\n",
            "\n",
            "Epoch 00019: loss improved from 0.60112 to 0.59342, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 20/40\n",
            "122769/122769 [==============================] - 84s 687us/step - loss: 0.5763 - acc: 0.8112\n",
            "\n",
            "Epoch 00020: loss improved from 0.59342 to 0.57630, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 21/40\n",
            "122769/122769 [==============================] - 84s 686us/step - loss: 0.5789 - acc: 0.8090\n",
            "\n",
            "Epoch 00021: loss did not improve from 0.57630\n",
            "Epoch 22/40\n",
            "122769/122769 [==============================] - 85s 693us/step - loss: 0.5695 - acc: 0.8135\n",
            "\n",
            "Epoch 00022: loss improved from 0.57630 to 0.56954, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 23/40\n",
            "122769/122769 [==============================] - 85s 694us/step - loss: 0.5715 - acc: 0.8109\n",
            "\n",
            "Epoch 00023: loss did not improve from 0.56954\n",
            "Epoch 24/40\n",
            "122769/122769 [==============================] - 85s 694us/step - loss: 0.5639 - acc: 0.8128\n",
            "\n",
            "Epoch 00024: loss improved from 0.56954 to 0.56392, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 25/40\n",
            "122769/122769 [==============================] - 85s 692us/step - loss: 0.5626 - acc: 0.8149\n",
            "\n",
            "Epoch 00025: loss improved from 0.56392 to 0.56263, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 26/40\n",
            "122769/122769 [==============================] - 85s 694us/step - loss: 0.5666 - acc: 0.8123\n",
            "\n",
            "Epoch 00026: loss did not improve from 0.56263\n",
            "Epoch 27/40\n",
            "122769/122769 [==============================] - 85s 693us/step - loss: 0.5643 - acc: 0.8137\n",
            "\n",
            "Epoch 00027: loss did not improve from 0.56263\n",
            "Epoch 28/40\n",
            "122769/122769 [==============================] - 85s 689us/step - loss: 0.5609 - acc: 0.8138\n",
            "\n",
            "Epoch 00028: loss improved from 0.56263 to 0.56094, saving model to /content/drive/My Drive/stephen_king2.hdf5\n",
            "Epoch 29/40\n",
            "122769/122769 [==============================] - 84s 686us/step - loss: 0.5696 - acc: 0.8110\n",
            "\n",
            "Epoch 00029: loss did not improve from 0.56094\n",
            "Epoch 30/40\n",
            "122769/122769 [==============================] - 84s 688us/step - loss: 0.5747 - acc: 0.8103\n",
            "\n",
            "Epoch 00030: loss did not improve from 0.56094\n",
            "Epoch 31/40\n",
            "122769/122769 [==============================] - 84s 688us/step - loss: 0.5642 - acc: 0.8125\n",
            "\n",
            "Epoch 00031: loss did not improve from 0.56094\n",
            "Epoch 32/40\n",
            "122769/122769 [==============================] - 85s 690us/step - loss: 0.5695 - acc: 0.8109\n",
            "\n",
            "Epoch 00032: loss did not improve from 0.56094\n",
            "Epoch 33/40\n",
            "122769/122769 [==============================] - 85s 688us/step - loss: 0.5821 - acc: 0.8071\n",
            "\n",
            "Epoch 00033: loss did not improve from 0.56094\n",
            "Epoch 34/40\n",
            "122769/122769 [==============================] - 84s 688us/step - loss: 0.5819 - acc: 0.8061\n",
            "\n",
            "Epoch 00034: loss did not improve from 0.56094\n",
            "Epoch 35/40\n",
            "122769/122769 [==============================] - 85s 690us/step - loss: 0.5924 - acc: 0.8031\n",
            "\n",
            "Epoch 00035: loss did not improve from 0.56094\n",
            "Epoch 36/40\n",
            "122769/122769 [==============================] - 85s 690us/step - loss: 0.5860 - acc: 0.8068\n",
            "\n",
            "Epoch 00036: loss did not improve from 0.56094\n",
            "Epoch 37/40\n",
            "122769/122769 [==============================] - 85s 688us/step - loss: 0.5991 - acc: 0.8015\n",
            "\n",
            "Epoch 00037: loss did not improve from 0.56094\n",
            "Epoch 38/40\n",
            "122769/122769 [==============================] - 84s 688us/step - loss: 0.5999 - acc: 0.8003\n",
            "\n",
            "Epoch 00038: loss did not improve from 0.56094\n",
            "Epoch 39/40\n",
            "122769/122769 [==============================] - 86s 701us/step - loss: 0.6040 - acc: 0.7998\n",
            "\n",
            "Epoch 00039: loss did not improve from 0.56094\n",
            "Epoch 40/40\n",
            "122769/122769 [==============================] - 86s 703us/step - loss: 0.6072 - acc: 0.7978\n",
            "\n",
            "Epoch 00040: loss did not improve from 0.56094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0820162be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYXGfFFYVhEv",
        "colab_type": "code",
        "outputId": "67eb191d-a025-4ae6-ed1f-af174162ab6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/stephen_king2.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO0Wg7ozOuJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=0.7):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bAuOA7xDfhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 'people clustered in small groups that had a tendency to break up and re-form with surprising speed. '\n",
        "sent = ''\n",
        "seed_encode = []\n",
        "text = ''\n",
        "for i in seed:\n",
        "  seed_encode.append(vocab_to_num[i])\n",
        "seed_encode = np.array(seed_encode)\n",
        "for i in range(500):\n",
        "  text = seed_encode[-seq_len:]\n",
        "  text = np.expand_dims(text,axis=0)\n",
        "  pred = model.predict(text)\n",
        "  pred = sample(pred[0])\n",
        "  seed_encode = np.append(seed_encode, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLfQdDRjNLnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "message = ''\n",
        "for i in seed_encode:\n",
        "  message += num_to_vocab[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFXji3pQNycU",
        "colab_type": "code",
        "outputId": "62fa68ff-ff73-446f-81ba-b778956691a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(message)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "people clustered in small groups that had a tendency to break up and re-form with surprising speed. looking out to be an undergrad named donald morris work and i passed all the look and looked at him. he was supposed to stay wiping across the water,\n",
            "but they were working and shittered back of its an\n",
            "appla night. the corpse in the grinder, expecting the crap outs.\n",
            "\n",
            "the counted in the second. jagged sallow sound over the way back on the way - at least aloud.\n",
            "\n",
            "i suspect there,' hall said softly. he was supposed to be our life counting fingers. renshaw sat on the thud that had a sudden goot of a n\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}